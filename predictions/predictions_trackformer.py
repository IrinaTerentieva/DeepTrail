import os
import yaml
import torch
import rasterio
import numpy as np
from tqdm import tqdm
from torch.utils.data import Dataset
from transformers import SegformerConfig, SegformerForSemanticSegmentation
import gc
import tempfile
import scipy.ndimage as ndimage

from rasterio.windows import Window

def generate_patch_indices(size, patch_size, overlap_size):
    """
    Generates a sorted list of start indices for patches such that
    the stride is (patch_size - overlap_size) but includes a final
    patch if needed so we don't miss coverage at the boundary.
    """
    stride = patch_size - overlap_size
    indices = []
    start = 0

    while True:
        # If the remaining region is smaller than patch_size, move the last patch
        # so it ends exactly at 'size'. That ensures full coverage.
        if start + patch_size >= size:
            final_start = max(size - patch_size, 0)
            indices.append(final_start)
            break

        indices.append(start)
        start += stride

    # Remove duplicates (in case of small sizes) and sort
    indices = sorted(set(indices))
    return indices

def normalize_nDTM(image, std=0.1):
    """Normalize image to the [0, 1] range."""
    min_val, max_val = -std, std
    image = np.clip(image, min_val, max_val)
    return (image - min_val) / (max_val - min_val)

def sliding_window_prediction(image_path, model, output_dir, patch_size, overlap_size, threshold=0.1):
    """
    Perform sliding window prediction on a single image using memmap for accumulation
    to reduce RAM usage. The logic is:
      1) We read the image in chunks (row_start..row_end, col_start..col_end).
      2) For each chunk, we run a sliding-window inference covering the entire chunk
         with patch indices generated by 'generate_patch_indices', ensuring boundary coverage.
      3) If a patch extends beyond chunk boundaries, we zero-pad it so the model always
         receives a patch_size x patch_size input.
      4) We accumulate results in accum_array and count_array (both memmaps).
      5) Finally, we iterate chunk-by-chunk again to compute final prob, threshold, remove
         small connected comps, scale to [0..100], and write to GeoTIFF.

    NOTE: Connected-component removal is chunk-local. If small features cross chunk boundaries,
    they won't be removed globally. For truly correct global CC removal, you'd need more memory
    or a streaming CC approach that merges boundaries.
    """

    with rasterio.open(image_path) as src:
        print(f"\n[INFO] Processing: {image_path}")

        # Basic metadata
        height, width = src.shape
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # Create memory-mapped arrays for accumulation and count
        temp_dir = tempfile.gettempdir()
        accum_path = os.path.join(temp_dir, "accumulation.dat")
        count_path = os.path.join(temp_dir, "count_array.dat")

        accumulation = np.memmap(accum_path, dtype=np.float32, mode='w+', shape=(height, width))
        count_array = np.memmap(count_path, dtype=np.int32, mode='w+', shape=(height, width))

        # Initialize
        accumulation[:] = 0.0
        count_array[:] = 0
        accumulation.flush()
        count_array.flush()

        # Decide chunk size for reading
        read_chunk_size = 2048  # adjust as you like

        # -------------------------
        # 1) CHUNK-BASED INFERENCE
        # -------------------------
        for row_start in tqdm(range(0, height, read_chunk_size), desc="Chunks (Inference)"):
            row_end = min(row_start + read_chunk_size, height)
            chunk_height = row_end - row_start

            for col_start in range(0, width, read_chunk_size):
                col_end = min(col_start + read_chunk_size, width)
                chunk_width = col_end - col_start

                # Read the chunk from disk
                window = Window(col_start, row_start, chunk_width, chunk_height)
                chunk_data = src.read(1, window=window)
                chunk_data = np.nan_to_num(chunk_data, nan=0.0)

                # Replace nodata with 0
                if src.nodata is not None:
                    chunk_data[chunk_data == src.nodata] = 0

                # Normalize
                chunk_data = normalize_nDTM(chunk_data)

                # Generate row/col indices for patches within this chunk
                row_indices = generate_patch_indices(chunk_height, patch_size, overlap_size)
                col_indices = generate_patch_indices(chunk_width, patch_size, overlap_size)

                # Slide patch-by-patch
                for i in row_indices:
                    for j in col_indices:
                        # Extract local patch from chunk
                        local_patch = chunk_data[i : i + patch_size, j : j + patch_size]

                        # This might be smaller than patch_size near boundaries
                        actual_patch_height, actual_patch_width = local_patch.shape

                        if actual_patch_height == 0 or actual_patch_width == 0:
                            continue

                        # If it's smaller, pad so model sees exactly patch_size x patch_size
                        if (actual_patch_height < patch_size) or (actual_patch_width < patch_size):
                            padded_patch = np.zeros((patch_size, patch_size), dtype=local_patch.dtype)
                            padded_patch[:actual_patch_height, :actual_patch_width] = local_patch
                            patch_for_model = padded_patch
                        else:
                            patch_for_model = local_patch

                        # If it's all zero, skip
                        if np.all(patch_for_model == 0):
                            continue

                        # Convert to tensor
                        tensor_patch = torch.from_numpy(patch_for_model).unsqueeze(0).unsqueeze(0).float().to(device)

                        # Forward pass
                        with torch.no_grad():
                            outputs = model(pixel_values=tensor_patch)
                            logits = outputs.logits
                            probabilities = torch.sigmoid(logits)
                            upsampled_probs = torch.nn.functional.interpolate(
                                probabilities,
                                size=(patch_size, patch_size),
                                mode="bilinear",
                                align_corners=False
                            )
                            prob_values = upsampled_probs.squeeze().cpu().numpy()

                        # Now we map back to the global offset in the memmaps
                        global_i = row_start + i
                        global_j = col_start + j

                        # We only accumulate the part that corresponds to the actual patch size
                        # (i.e. no need to accumulate padded region beyond the chunk if chunk was small)
                        accumulation[global_i : global_i + actual_patch_height,
                                     global_j : global_j + actual_patch_width] += prob_values[:actual_patch_height,
                                                                                              :actual_patch_width]
                        count_array[global_i : global_i + actual_patch_height,
                                    global_j : global_j + actual_patch_width] += 1

                        # Cleanup
                        del tensor_patch, outputs, logits, probabilities, upsampled_probs, prob_values
                        torch.cuda.empty_cache()

                # flush memmaps
                accumulation.flush()
                count_array.flush()

        # ---------------------------------------
        # 2) CHUNK-BASED FINAL WRITING TO DISK
        # ---------------------------------------
        output_filename = os.path.splitext(os.path.basename(image_path))[0] + '_trailformer_ep18_v.3.22upd.tif'
        # output_filename = os.path.splitext(os.path.basename(image_path))[0] + '_trailformer_ep11_v.3.tif'

        output_path = os.path.join(output_dir, output_filename)

        new_profile = src.profile.copy()
        new_profile.update({
            'driver': 'GTiff',
            'dtype': 'uint8',
            'count': 1,
            'compress': 'lzw'
        })
        # remove invalid nodata for uint8
        new_profile.pop('nodata', None)

        with rasterio.open(output_path, 'w', **new_profile) as dst:
            write_chunk_size = 1024  # chunk size for writing

            for row_start in tqdm(range(0, height, write_chunk_size), desc="Chunks (Write)"):
                row_end = min(row_start + write_chunk_size, height)
                chunk_height = row_end - row_start

                for col_start in range(0, width, write_chunk_size):
                    col_end = min(col_start + write_chunk_size, width)
                    chunk_width = col_end - col_start

                    # Grab accum + count from memmaps
                    accum_chunk = accumulation[row_start:row_end, col_start:col_end]
                    count_chunk = count_array[row_start:row_end, col_start:col_end]

                    # Compute final probabilities
                    with np.errstate(divide='ignore', invalid='ignore'):
                        prob_chunk = accum_chunk / np.maximum(count_chunk, 1)

                    # Threshold
                    bin_mask_chunk = (prob_chunk >= threshold).astype(np.uint8)

                    # Optional local connected-component removal
                    labeled_chunk, num_features_chunk = ndimage.label(bin_mask_chunk)
                    component_sizes = ndimage.sum(bin_mask_chunk, labeled_chunk,
                                                  index=range(1, num_features_chunk + 1))
                    too_small = [idx for idx, size in enumerate(component_sizes, start=1)
                                 if size < 200]
                    if too_small:
                        too_small_set = set(too_small)
                        bin_mask_chunk[np.isin(labeled_chunk, list(too_small_set))] = 0

                    # Zero out probabilities outside mask
                    prob_chunk[bin_mask_chunk == 0] = 0.0

                    # Scale by 100, convert to uint8
                    scaled_chunk = (prob_chunk * 100).astype(np.uint8)

                    # Write to disk
                    window = Window(col_start, row_start, chunk_width, chunk_height)
                    dst.write(scaled_chunk, 1, window=window)

        # Cleanup
        del accumulation, count_array
        gc.collect()

        print(f"[INFO] Prediction saved to {output_path}")
        return output_path

def load_configuration():
    base_dir = '/home/irina/HumanFootprint'
    config_path = os.path.join(base_dir, 'config_segformer.yaml')
    print(f"[INFO] Loading configuration from {config_path}")
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    return config, base_dir

def load_model(config, base_dir):
    prediction_params = config['prediction_params']
    model_path = os.path.join(base_dir, prediction_params['model_path'])

    # Overwrite the actual path if needed
    model_path = '/home/irina/HumanFootprint/HF_models/TrackFormer_HumanFootprint_dataset_1024_nDTM10cm_arch_mit-b2_lr_0.001_batch_4_epoch_18_v.3.22/pytorch_model_weights.pth'
    # model_path = '/home/irina/HumanFootprint/HF_models/TrackFormer_HumanFootprint_dataset_1024_nDTM10cm_arch_mit - b2_lr_0.001_batch_4_epoch_11_v.3/pytorch_model_weights.pth'


    print(f"[INFO] Loading Model from: {model_path}")

    model_config = config['models']['mit-b2']
    config_obj = SegformerConfig(
        num_labels=1,
        depths=model_config['depths'],
        hidden_sizes=model_config['hidden_sizes'],
        decoder_hidden_size=model_config['decoder_hidden_size'],
        aspp_ratios=model_config.get('aspp_ratios', [1, 6, 12, 18]),
        aspp_out_channels=model_config.get('aspp_out_channels', 256),
        attention_probs_dropout_prob=model_config.get('attention_dropout_prob', 0.1),
    )

    model = SegformerForSemanticSegmentation(config_obj)

    # Modify first conv layer to accept single-channel input
    model.segformer.encoder.patch_embeddings[0].proj = torch.nn.Conv2d(
        in_channels=1,
        out_channels=model.segformer.encoder.patch_embeddings[0].proj.out_channels,
        kernel_size=model.segformer.encoder.patch_embeddings[0].proj.kernel_size,
        stride=model.segformer.encoder.patch_embeddings[0].proj.stride,
        padding=model.segformer.encoder.patch_embeddings[0].proj.padding,
        bias=False
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    model.to(device)
    return model

def run_prediction():
    config, base_dir = load_configuration()

    prediction_params = config['prediction_params']
    test_image_path = os.path.join(base_dir, prediction_params['test_image_path'])
    # Overwrite with your actual test image path if needed
    test_image_path = '/media/irina/data/ndtm_original/'
    # test_image_path = '/media/irina/My Book/Surmont/nDTM_synth_trails/nDTM_10cm_trails_v2/502_6223_nDTM_blended_synth_trails_v5.tif'
    # test_image_path = '/media/irina/data/Kirby/nDTM/Airborne/Kirby_nDTM10cm_mean6m.tif'

    output_dir = os.path.join(base_dir, prediction_params['output_dir'])
    output_dir = '/media/irina/data/Kirby/Products/Trails/Kirby_nDTM10cm_mean6m_TrackFormer_epoch_18_v.3.22upd'
    # output_dir = '/media/irina/My Book/Surmont/Products/Trails/TrackFormer_HumanFootprint_dataset_1024_nDTM10cm_arch_mit-b2_lr_0.001_batch_4_epoch_11_v.3'

    os.makedirs(output_dir, exist_ok=True)

    patch_size = prediction_params['patch_size']
    overlap_size = prediction_params['overlap_size']
    threshold = 0.1  # or 0.3, up to you

    print("\n*********\nConfiguration:")
    print(f"Test Image Path: {test_image_path}")
    print(f"Output Directory: {output_dir}")
    print(f"Patch Size: {patch_size}")
    print(f"Overlap Size: {overlap_size}")
    print(f"Threshold for final predictions: {threshold}")

    model = load_model(config, base_dir)

    # If test_image_path is directory, list TIF files. Otherwise, it's a single file
    if os.path.isdir(test_image_path):
        image_files = [os.path.join(test_image_path, f)
                       for f in os.listdir(test_image_path) if f.lower().endswith('.tif')]
    else:
        image_files = [test_image_path]

    print(f"\n[INFO] Found {len(image_files)} images for prediction")
    for img_path in image_files:
        sliding_window_prediction(
            img_path,
            model,
            output_dir,
            patch_size=patch_size,
            overlap_size=0,
            threshold=threshold
        )

def main():
    print("[INFO] Starting Segformer Prediction Flow")
    run_prediction()
    print("[INFO] Prediction flow completed.")

if __name__ == '__main__':
    main()
