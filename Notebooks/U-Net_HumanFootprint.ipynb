{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf  \n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import fiona\n",
    "import datetime\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "import tensorflow_addons as tfa\n",
    "import rasterio\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "from FUNCTIONS_Seedlings import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the list of physical devices\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Configure memory growth for each physical device\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two possible solutions are to change config.gpu_options.per_process_gpu_memory_fraction to a greater number.\n",
    "\n",
    "The other solutions were to reinstall cuda.\n",
    "\n",
    "https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "    tf.config.experimental.set_virtual_device_configuration(physical_devices[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '/gpu:0'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.nvidia.com/rdp/cudnn-archive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def filter_location(tif, tif_array, mask):\n",
    "    '''READING raster with original data (tif) and label layer (mask) as numpy arrays & \n",
    "       FILTERING the boundaries of label layer using original tif layer.\n",
    "       \n",
    "       E.g. you produced tiled CHM for Surmont and have a label layer with wellpads (value 1) \n",
    "       and other areas (value 0) for the whole Surmont area. You planning to work with numpy arrays (no coordinates!)\n",
    "       so you need first to be sure that you have tiled tif and the label of the exact same shape and areal coverage.\n",
    "       In this case, you're cropping label layer (mask) using boundaries of your tiled original CHM (tif).\n",
    "    \n",
    "    tif:      Initial raster Layer with Nband - number of bands (1 by default)\n",
    "    \n",
    "    mask:     Label layer with EVERY pixel having a value of 1\n",
    "              for object (e.g. line footprint in case of line mapping)\n",
    "              and 0 for the rest area (e.g. lake, forest, peatland)\n",
    "              Label should be of the same resolution as \"tif\"\n",
    "    '''\n",
    "    \n",
    "    Nband = 1      #### CHANGE if needed\n",
    "\n",
    "    ##### Getting its bounds (usually it has larger area that tiled \"tif\" layer)\n",
    "    mask_left, mask_bottom, mask_right, mask_top = mask.bounds\n",
    "    print('\\nlabel layer bounds: ', mask.bounds)\n",
    "    \n",
    "    ##### Getting resolution of label layer (should be the same for tif and mask!)\n",
    "    resolution = mask.res[0] ####\n",
    "    print(resolution)\n",
    "    \n",
    "    ##### Calculating relative beginning of tif layer comparing to larger mask area\n",
    "    bottom_new = int((mask_top - top) / resolution)\n",
    "    height = int((top - bottom) / resolution)\n",
    "    left_new = int((left-mask_left)/resolution)\n",
    "    width = int((right - left) / resolution)\n",
    "    print('NEW coverage is from {} + {} and from {} to {}'.format(bottom_new, height, left_new, width))\n",
    "    \n",
    "    ##### Reading label layer as numpy array\n",
    "    mask_array = mask.read()\n",
    "    print('Shape of mask array:', mask_array.shape)\n",
    "    \n",
    "    ##### Cropping label layer to be fully coaligned with original tif layer\n",
    "    mask_array = mask_array[bottom_new:bottom_new+height, left_new:left_new+width]\n",
    "    print('Shape of mask array:', mask_array.shape)\n",
    "    return tif_array, mask_array"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def label_list(folder, ending_img, ending_label):\n",
    "    '''Making lists of training images and corresponding labels located in the directory. \n",
    "       For example, you have 10 png pictures with CHM and 10 png pictures with label layer and you want to make\n",
    "       two lists, first with training CHM patches and second - with corresponding label layers. \n",
    "       \n",
    "       folder: root directory with both training images and the corresponding labels\n",
    "       ending_img:   training images ends with...? e.g. \"rgb_256.png\"\n",
    "       ending_label: training labels ends with...? e.g. \"label_256.png\"\n",
    "       \n",
    "       Output:\n",
    "       rgb_fls: list of training images (full path)\n",
    "       label_fls: list of their labels (full path)\n",
    "       '''\n",
    "    \n",
    "    ##### Preparing list of training images within the folder\n",
    "    rgb_fls = [os.path.join(folder,files) for files in os.listdir(folder) if files.endswith(str(ending_img))]\n",
    "    \n",
    "    ##### Making the list of corresponding label patches\n",
    "    label_fls = []\n",
    "\n",
    "    for i in range(len(rgb_fls)):\n",
    "        name = str(os.path.basename(rgb_fls[i])[:-len(ending_img)])+str(ending_label)\n",
    "        if not os.path.exists(os.path.join(folder,name)):\n",
    "            print(name)\n",
    "            print('Oooops! Check the path!')\n",
    "        label_fls.append(os.path.join(folder,name))\n",
    "    return rgb_fls, label_fls\n",
    "\n",
    "def checks(arr, norm = True):\n",
    "    '''Simple checks for patches: they should be squarish and normilizes (if norm = TRUE)'''\n",
    "    error = 0\n",
    "    ##### Check have we normilized our image?\n",
    "    if norm == True and arr.max() > 1:\n",
    "        print('Houston, we have got a problem with 255!')\n",
    "        error = 1\n",
    "    ##### Check is it square patch?\n",
    "    if arr.shape[0]!=arr.shape[1]:\n",
    "        print('Houston, we have got a problem with shape!')\n",
    "        error = 1\n",
    "    return error\n",
    "\n",
    "def norm(path, greyscale=False):\n",
    "    '''Image normalization: first we read image using cv2 (greyscale or rgb), then we normilize it (up to 1)\n",
    "    path: path to your greyscale or rgb image (usually .png)\n",
    "    greyscale: check if yes\n",
    "    \n",
    "    output: normilized image\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ##### Reading the single image\n",
    "    if greyscale == False:\n",
    "        image = cv2.imread(path, cv2.IMREAD_COLOR)  # uint8 image\n",
    "    else:\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  # uint8 image\n",
    "        print(image.shape)\n",
    "        \n",
    "    ##### Normilization of the image\n",
    "    norm_image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    print('The max value was {}, we nomalize it to {}'.format(image.max(), norm_image.max()))\n",
    "    return norm_image\n",
    "\n",
    "def shp_to_patches(shp, tif, src, size = 256):\n",
    "    '''\n",
    "    Transforming our shapefile with points to the pandas dataframe with patches (squares) around them!\n",
    "    & Filtering shp by boundaries of the tif file.\n",
    "    \n",
    "    Input\n",
    "    shp:          shapefile with (usually random) points. We'll build our training patches around them\n",
    "    tif_path:     full path to original tif file with your data\n",
    "    size:         size of your output patches (e.g. 256 pix * 256 pix)\n",
    "    \n",
    "    Output\n",
    "    result:  pandas dataframe with 'image_path' of your original tif, \n",
    "             boundaries and center coordinates (minx, miny - non geographic, tile_xmin, tile_ymin - geographical)\n",
    "             and your label (only for object detection).\n",
    "    '''\n",
    "\n",
    "    left, bottom, right, top = src.bounds\n",
    "    resolution = src.res[0]\n",
    "    print('RGB shape', tif.shape)\n",
    "    print('Bounds: ', src.bounds)\n",
    "        \n",
    "    # Read shapefile\n",
    "    gdf = gpd.read_file(shp)\n",
    "    \n",
    "    ##### Filtering shapefile by tif boundaries\n",
    "    print('Initial number of points: ', len(gdf))\n",
    "    gdf = gdf.geometry.bounds\n",
    "    gdf = gdf[gdf.minx > left]\n",
    "    gdf = gdf[gdf.minx < right]\n",
    "    gdf = gdf[gdf.miny > bottom]\n",
    "    gdf = gdf[gdf.miny < top]\n",
    "    df = gdf.copy()\n",
    "    print('Final number of points: ', len(gdf))\n",
    "    \n",
    "    # add filename\n",
    "    df[\"image_path\"] = os.path.basename(tif_path)\n",
    "    print('Total number of points is ', len(df))\n",
    "    \n",
    "    # Transform project coordinates to image coordinates\n",
    "    size = int(size/2)\n",
    "    df[\"tile_x\"] = (df.minx - left) / resolution\n",
    "    df[\"center_x\"] = df[\"tile_x\"].astype(int)\n",
    "    df[\"tile_xmin\"] = df[\"tile_x\"]-size\n",
    "    df[\"tile_xmax\"] = df[\"tile_x\"]+size\n",
    "\n",
    "    # UTM is given from the top, but origin of an image is top left\n",
    "    df[\"tile_y\"] = (top - df.miny) / resolution\n",
    "    df[\"center_y\"] = df[\"tile_y\"].astype(int)\n",
    "    df[\"tile_ymin\"] = df[\"tile_y\"]-size\n",
    "    df[\"tile_ymax\"] = df[\"tile_y\"]+size\n",
    "    \n",
    "    print('Filtering tile x by...', tif.shape[2])\n",
    "    print('Filtering tile y by...', tif.shape[1])\n",
    "\n",
    "    df = df[df.tile_x < tif.shape[2]]\n",
    "    df = df[df.tile_y < tif.shape[1]]\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        df.loc[index, 'label'] = tif[0, int(row.tile_y), int(row.tile_x)]\n",
    "        \n",
    "    # select columns\n",
    "    result = df[[\n",
    "        \"image_path\", \"minx\", \"miny\", \"center_x\", \"center_y\", 'tile_xmin', 'tile_ymin'\n",
    "    ]]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def patch_crop(array, mask, df, idnumber, size = 256, base_dir = '/media/irro/Irro/Irina/WellPads/wellpads_res05_512'):\n",
    "    ''' Cropping patches to training images and labels of the certain size\n",
    "        & saving the to the directory\n",
    "        \n",
    "        Input\n",
    "        array:     original tif file (e.g. our CHM) read as numpy array\n",
    "        mask:      corresponding label layer (e.g. pixel-wise mask of lines and non lines) read as nunpy array\n",
    "        df:        pandas dataframe with coordinates of final patches we need to crop (by def shp_to_patches)\n",
    "        idnumber:  init number of patch we use when saving it (e.g. patch_661.png means idnumber = 661)\n",
    "        base_dir:  directory to save our patches!\n",
    "        \n",
    "        No output needed: check base_dir with patches.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    ##### Iterating over dataframe to crop patches of image and label:\n",
    "    num = 0\n",
    "    for index, row in df.iterrows():\n",
    "        patch = array[int(row.center_y-size/2):int(row.center_y+size/2), int(row.center_x-size/2):int(row.center_x+size/2)]\n",
    "        patch_l = mask[int(row.center_y-size/2):int(row.center_y+size/2), int(row.center_x-size/2):int(row.center_x+size/2)]\n",
    "        \n",
    "#         print(patch.shape)\n",
    "#         print(patch_l.shape)\n",
    "        \n",
    "        #### Miss patches if they are not squares\n",
    "        if patch.shape[0] != size or patch.shape[1] != size:\n",
    "            continue  \n",
    "        #### Miss patches if they are not squares \n",
    "        if patch_l.shape[0] < 100 or patch_l.shape[1] < 100:\n",
    "            continue  \n",
    "        \n",
    "        patch = (patch - patch.min()) * (255.0 / (patch.max() - patch.min()))\n",
    "        \n",
    "        #### Change axis to fit for cv2 saving format:\n",
    "        patch = np.moveaxis(patch, 0, -1) \n",
    "        patch_l = np.moveaxis(patch_l, 0, -1) \n",
    "        \n",
    "      \n",
    "            \n",
    "        ##### Preparing FILENAMES for our patches! You may want to change this!        \n",
    "        filename_p = \"{}/{}_{}_{}.png\".format(base_dir, 'line_patches', idnumber, 'rgb')\n",
    "        filename_l = \"{}/{}_{}_{}.png\".format(base_dir, 'line_patches', idnumber, 'lab')\n",
    "        \n",
    "        print(filename_p)\n",
    "#         print(filename_l)\n",
    "        \n",
    "        ##### SAVING patches into the folder (individually, training image and label)\n",
    "        cv2.imwrite(filename_p, patch)\n",
    "        cv2.imwrite(filename_l, patch_l)\n",
    "        \n",
    "        #### Counting patches and increasing index (so the next file will have +1 idnumber)\n",
    "        num = num+1\n",
    "        idnumber = idnumber+1\n",
    "\n",
    "    print('The number of patches is', num)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def patch_in_batch(shp, tif_path, mask, size, base_dir, idnumber = 0):\n",
    "    '''Function for cropping patches from the beginning. The same procedure for every tile:\n",
    "    1) shapefile with points to dataframe with square coordinate WITHIN the tile boundaries\n",
    "    2) reading tif_path and label layer to numpy array & filtering their boundaries to make correspond to each other\n",
    "    with their shapes and covered area\n",
    "    3) Vizualization just to check that everythin is right\n",
    "    4) Cropping patches using dataframe and saving them to the base_dir\n",
    "    \n",
    "    Input\n",
    "    shp:          shapefile with (usually random) points. We'll build our training patches around them\n",
    "    tif_path:     full path to original tif file with your data\n",
    "    mask:         Label layer with EVERY pixel having a value of 1\n",
    "                  for object (e.g. line footprint in case of line mapping)\n",
    "                  and 0 for the rest area (e.g. lake, forest, peatland)\n",
    "                  Label should be of the same resolution as \"tif\"\n",
    "    size:         size of your output patches (e.g. 256 pix * 256 pix) \n",
    "    base_dir:     directory to save our patches!\n",
    "    idnumber:     init number of patch we use when saving it (e.g. patch_661.png means idnumber = 661)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    df = shp_to_patches(shp, tif_path)\n",
    "    print('\\nNumber of points within the shapefile is {}'.format(len(df)))\n",
    "    \n",
    "    rgb_array, mask_array = filter_location(tif_path, mask)\n",
    "    \n",
    "    ### IMPORTANT: If Lable != 1, you should change its value to 1 and non-ROI to 0\n",
    "    mask_array = np.where(mask_array==0, 1, 0).astype(np.uint8)\n",
    "    \n",
    "    # Prediction vizualization:\n",
    "    f, axarr = plt.subplots(1,2,figsize=(20,20))\n",
    "    axarr[0].imshow(rgb_array[:500,:500])\n",
    "    axarr[1].imshow(mask_array[:500,:500])\n",
    "    \n",
    "    patch = patch_crop(rgb_array, mask_array, df, \n",
    "            idnumber = idnumber, size = size, \n",
    "            base_dir = base_dir)    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patching"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_dir = '/media/irro/Irro/HumanFootprint/'\n",
    "\n",
    "##### List of tif files in the folder\n",
    "mask_list = [os.path.join(train_dir,files) for files in os.listdir(train_dir) if files.startswith(\"Kirby_DSM_10cm_lab\")\n",
    "           and files.endswith('.tif')]\n",
    "\n",
    "##### Check that you're reading only needed files\n",
    "print(mask_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### Train images and labels should correspond to each other within the list!\n",
    "#### That's why sometimes it's easier to read label list and then just add right extension to it:\n",
    "\n",
    "tif_list=[]\n",
    "for x in mask_list:\n",
    "#     print(x)\n",
    "    path = x[:-11]+x[-7:]\n",
    "    if not os.path.exists(path):\n",
    "        print('Ooops with {}'.format(path))\n",
    "    tif_list.append(path)\n",
    "print(tif_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tif List"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_dir = '/media/irro/Irro/HumanFootprint/Training_Images_256'\n",
    "\n",
    "##### List of tif files in the folder\n",
    "mask_list = [os.path.join(train_dir,files) for files in os.listdir(train_dir) if files.endswith('.tif')]\n",
    "\n",
    "##### Check that you're reading only needed files\n",
    "print(tif_list)\n",
    "print(mask_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Nband = 1      #### CHANGE if needed\n",
    "i=0\n",
    "size = 256\n",
    "patch_dir = '/media/irro/Irro/HumanFootprint/Training_256_cnn'\n",
    "shp = '/media/irro/Irro/HumanFootprint/random_cnn_lots.shp'\n",
    "\n",
    "if not os.path.exists(patch_dir):\n",
    "    os.makedirs(patch_dir)    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for tif_path in tif_list:\n",
    "    ##### Reading tif raster using rasterio (usually it's a tile, not the whole image)\n",
    "    tif = rasterio.open(tif_path)\n",
    "    print(tif_path)\n",
    "    print(mask_list[i])\n",
    "    \n",
    "    ##### Getting raster bounds (in geo coordinates)\n",
    "    left, bottom, right, top = tif.bounds\n",
    "    ##### Reading tif as numpy array\n",
    "    tif_array = tif.read()#.astype(np.float32)\n",
    "    ##### Printing its shape and bounds\n",
    "    print('tif array shape', tif_array.shape)\n",
    "    print('tif bounds: ', tif.bounds)\n",
    "    ##### Reading LABEL layer\n",
    "\n",
    "    ### CHANGE\n",
    "    mask = rasterio.open(mask_list[i])\n",
    "    \n",
    "    \n",
    "    ##### Getting its bounds (usually it has larger area that tiled \"tif\" layer)\n",
    "    mask_left, mask_bottom, mask_right, mask_top = mask.bounds\n",
    "    print('\\nlabel layer bounds: ', mask.bounds)\n",
    "\n",
    "    ##### Getting resolution of label layer (should be the same for tif and mask!)\n",
    "    resolution = mask.res[0] ####\n",
    "    print(resolution)\n",
    "\n",
    "    ##### Calculating relative beginning of tif layer comparing to larger mask area\n",
    "    bottom_new = int((mask_top - top) / resolution)\n",
    "    height = int((top - bottom) / resolution)\n",
    "    left_new = int((left-mask_left)/resolution)\n",
    "    width = int((right - left) / resolution)\n",
    "    print('NEW coverage is from {} + {} and from {} to {}'.format(bottom_new, height, left_new, width))\n",
    "\n",
    "    ##### Reading label layer as numpy array\n",
    "    mask_array = mask.read().astype(np.uint8)\n",
    "    print('Shape of mask array:', mask_array.shape)\n",
    "\n",
    "    ##### Cropping label layer to be fully coaligned with original tif layer\n",
    "    mask_array = mask_array[bottom_new:bottom_new+height, left_new:left_new+width]\n",
    "    print('Shape of mask array:', mask_array.shape)\n",
    "\n",
    "    df = shp_to_patches(shp, tif_array, tif, size = size)\n",
    "    rgb_array, mask_array = filter_location(tif, tif_array, mask)\n",
    "\n",
    "    normalized_array = (rgb_array-rgb_array.min())\n",
    "    \n",
    "    patch = patch_crop(normalized_array[0,:,:], mask_array[0,:,:], df, \n",
    "            idnumber = i*2000, size = size, \n",
    "            base_dir = patch_dir)        \n",
    "    \n",
    "    i=i+1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad pairs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Set the directory path where the image pairs are located\n",
    "directory = '/media/irro/Irro/HumanFootprint/Training_256_cnn/'\n",
    "\n",
    "i=0\n",
    "\n",
    "# Iterate over the files in the directory\n",
    "for file_name in os.listdir(directory):\n",
    "    if file_name.endswith('_rgb.png'):\n",
    "        # Get the corresponding label image file\n",
    "        label_file = os.path.join(directory, file_name.replace('_rgb.png', '_lab.png'))\n",
    "        \n",
    "        # Open the label image\n",
    "        label_image = Image.open(label_file)\n",
    "        \n",
    "        # Count the number of pixels with a value of 1\n",
    "        count = sum(1 for pixel in label_image.getdata() if pixel == 1)\n",
    "    \n",
    "        # Check if the count is less than 50\n",
    "        if count < 500:\n",
    "            # Delete the image pair\n",
    "            os.remove(os.path.join(directory, file_name))\n",
    "            os.remove(label_file)\n",
    "            print('Removed')\n",
    "            i = i+1\n",
    "\n",
    "print(i)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means that when you are loading PNG, you are loading it wrong. If you have 1 class, the masks should be loaded as greyscale (1 channel), with values between 0 and 1 (most often only 0s and 1s). If there are mask values greater than 1, the Binary Cross Entropy is confused...\n",
    "solution:  im = resize_and_crop(Image.open(dir + id + suffix), scale=scale) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Tensorflow record file consists of serialised messages which is a dictionary of a feature label and its associated value. To convert images into TFrecord files we utilize the protocol tensorflow.train.Example\n",
    "\n",
    "Steps 1:\n",
    "\n",
    "    Break down the image into smaller images (tiling)\n",
    "    Create helper functions to cast datatypes into 1 of the type lists (integer,float and bytes)\n",
    "    Create a feature dictionary which will be the contents of message. This is how we associate the image to the mask\n",
    "    Convert the features into to bytes, a process called serialization\n",
    "    Add the features to a message\n",
    "    Create a tfrecord file and write the messages (image and its associated features) to it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### https://www.kaggle.com/code/uysalserkan/uav-dataset-reading-augmentation/notebook?scriptVersionId=53034343"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### Root folder with training data: labels and images\n",
    "train_folder = patch_dir\n",
    "print(train_folder)\n",
    "train_images = [os.path.join(train_folder,files) for files in os.listdir(train_folder) if files.endswith(\"rgb.png\") and not files.endswith(\"lab.png\")]\n",
    "train_labels = [os.path.join(train_folder,files) for files in os.listdir(train_folder) if files.endswith(\"lab.png\") and not files.endswith(\"rgb.png\")]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### Train images and labels should correspond to each other within the list!\n",
    "#### That's why sometimes it's easier to read label list and then just add right extension to it:\n",
    "\n",
    "train_images=[]\n",
    "for x in train_labels:\n",
    "#     print(x)\n",
    "    path = x[:-7]+str('rgb.png')\n",
    "    train_images.append(path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### We should have THE SAME number of labels and train images\n",
    "print('We have {} train images and {} trains labels\\nwith the size of {}'.format(len(train_images), len(train_labels), np.array(Image.open(train_images[1])).shape))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### Checking image-label pairs!\n",
    "n = np.random.randint(len(train_images))\n",
    "print(train_images[n])\n",
    "print(train_labels[n])\n",
    "\n",
    "if not os.path.exists(train_images[n]) or not os.path.exists(train_labels[n]):\n",
    "    print(name)\n",
    "    print('Oooops! NO FILE')\n",
    "else:\n",
    "    print('\\nBoth files exists... check the pair! image and label should have the same idnumber')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "f, axarr = plt.subplots(1,2,figsize=(20,20))\n",
    "n = np.random.randint(len(train_images))\n",
    "print(n)\n",
    "axarr[0].imshow(np.array(Image.open(train_images[n])))\n",
    "axarr[1].imshow(np.array(Image.open(train_labels[n])))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing from kz-whale-tails"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "############## INPUT DATA\n",
    "\n",
    "### CHECK IF YOU NEED RESIZING\n",
    "### size of the training patch (usually 2**x): your original training images WILL BE RESIZED to this size\n",
    "size =256\n",
    "rs = 1\n",
    "\n",
    "# rs = int(np.array(Image.open(train_images[1])).shape[0]/size)\n",
    "print('IF RESIZING, you need to use resizing coefficient rs = {}'.format(rs))\n",
    "\n",
    "# how many patches model will see during the one step (usually 8-16-32)\n",
    "batch_size = 8"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### Readings png images to numpy array with the shape: (N of images, size, size)\n",
    "imgs_list = []\n",
    "masks_list = []\n",
    "\n",
    "### RESIZING patches to fit into computational resources\n",
    "for image, mask in zip(train_images, train_labels):\n",
    "    imgs_list.append(np.array(Image.open(image).resize((size,size))))\n",
    "    masks_list.append(np.array(Image.open(mask).resize((size,size))))\n",
    "imgs_np = np.asarray(imgs_list)\n",
    "masks_np = np.asarray(masks_list)\n",
    "\n",
    "print(imgs_np.shape, masks_np.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "############ PLOTTING original tif data (e.g. CHM), the corresponding label layer and their overlay!\n",
    "from keras_unet.utils import plot_imgs\n",
    "plot_imgs(org_imgs=imgs_np, mask_imgs=masks_np, nm_img_to_plot=10, figsize=6)\n",
    "\n",
    "print(imgs_np.max(), masks_np.max())\n",
    "#### IMPORTANT: original and ground truth should CORRESPOND to each other!"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### Normalizing images by dividing to 255:\n",
    "x = np.asarray(imgs_np, dtype=np.float32)/255\n",
    "#### Reading label layer as numpy array\n",
    "y = np.asarray(masks_np, dtype=np.float32)\n",
    "\n",
    "#### Reshaping to fit the model\n",
    "y = y.reshape(y.shape[0], y.shape[1], y.shape[2], 1)\n",
    "x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)\n",
    "\n",
    "print(x.shape, y.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Val Split"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, random_state=0)\n",
    "\n",
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_val: \", x_val.shape)\n",
    "print(\"y_val: \", y_val.shape)\n",
    "\n",
    "len_train = len(x_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from keras_unet.utils import get_augmented\n",
    "\n",
    "train_gen = get_augmented(\n",
    "    x_train, y_train, batch_size=batch_size,\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=360.,\n",
    "#         width_shift_range=0.05,\n",
    "#         height_shift_range=0.05,\n",
    "#         shear_range=40,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='constant'\n",
    "    ))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "sample_batch = next(train_gen)\n",
    "xx, yy = sample_batch\n",
    "print(xx.shape, yy.shape)\n",
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "plot_imgs(org_imgs=xx, mask_imgs=yy, nm_img_to_plot=10, figsize=5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('Input Shape: ', x_train[0].shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from keras_unet.models import custom_unet\n",
    "\n",
    "input_shape = x_train[0].shape\n",
    "# input_shape = (None, None, 1)\n",
    "\n",
    "# input_shape = (None, 512, 512, 1)\n",
    "\n",
    "model = custom_unet(\n",
    "    input_shape,\n",
    "    filters=32,\n",
    "    use_batch_norm=True,\n",
    "    dropout=0.3,\n",
    "#     dropout_change_per_layer=0.0,\n",
    "    num_classes=1,\n",
    "    output_activation='sigmoid',\n",
    "    num_layers=4\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance\n",
    "\n",
    "model_filename = '/media/irro/Irro/CNN_Models/human_lots_{}.h5'.format(size)\n",
    "\n",
    "callback_checkpoint = ModelCheckpoint(\n",
    "    model_filename, \n",
    "    verbose=1, \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    #optimizer=SGD(lr=0.01, momentum=0.99),\n",
    "    loss='binary_crossentropy',\n",
    "#     loss=jaccard_distance,\n",
    "    metrics=[iou, iou_thresholded]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training starts here..."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=int(len_train/batch_size),\n",
    "    epochs=1,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[callback_checkpoint]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# from keras_unet.utils import plot_segm_history\n",
    "# plot_segm_history(history)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import cv2\n",
    "\n",
    "path = '/media/irro/Irro/HumanFootprint/test.tif'\n",
    "data = tiff.imread(path)[:256, :256]\n",
    "\n",
    "# Preprocess the data\n",
    "patch = (data - data.min())\n",
    "patch = (patch - patch.min()) * (255.0 / (patch.max() - patch.min()))\n",
    "data = np.asarray(patch, dtype=np.float32) / 255\n",
    "# print(data.shape)\n",
    "# Expand dimensions to match the model's input shape\n",
    "input_data = np.expand_dims(data, axis=0)\n",
    "input_data = np.expand_dims(input_data, axis=-1)\n",
    "print(input_data.shape)\n",
    "\n",
    "# Perform prediction\n",
    "pred = model.predict(input_data) * 100\n",
    "# print(pred.shape)\n",
    "pred = np.squeeze(pred).astype(np.uint8)\n",
    "\n",
    "# Prediction visualization\n",
    "plt.imshow(pred, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# # Save the prediction as an image\n",
    "# # cv2.imwrite('/media/irro/Irro/HumanFootprint/test_CNN.png', pred)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE the Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# size = 256\n",
    "model_name = '/media/irro/Irro/CNN_Models/Human_lots_{}_byCNN_test.h5'.format(size)\n",
    "print(model_name)\n",
    "\n",
    "### Saving the model! Careful!\n",
    "# model.save(model_name)\n",
    "# print(model_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD the Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# model_name = '/media/irro/Irro/CNN_Models/WellPads_big_batch8_256.h5'\n",
    "# model.load_weights(model_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "##### Predict validation images\n",
    "y_pred = model.predict(x_val[0:10], batch_size=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "plot_imgs(org_imgs=x_val, mask_imgs=y_val, pred_imgs=y_pred, nm_img_to_plot=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import slidingwindow\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "\n",
    "def resize_arr(arr, rs):\n",
    "    '''Resizing array using PIL.Image module\n",
    "    arr:  one-band numpy array for resizing\n",
    "    rs:   resizing coefficient (rs = 4 than we changing size 4 times, e.g. from 1024 to 256)\n",
    "    \n",
    "    Output: resized numpy array\n",
    "    '''\n",
    "    ### Reading numpy array as PIL Image\n",
    "    img = Image.fromarray(arr)\n",
    "    ### Resizing as Image\n",
    "    data1 = img.resize(size=(int(arr.shape[0]/rs), int(arr.shape[1]/rs)))\n",
    "    ### Reading back to numpy array\n",
    "    data1 = np.array(data1)\n",
    "    return data1\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def predict_tif(model, path, size):\n",
    "    '''\n",
    "    Since Model training requires computational resources, it may NOT work with large tiles as 1024 pixels.\n",
    "    But, to predict objects like seismic lines, we need big tiles for visibility.\n",
    "    To address this problem, we can first downscale our tiles, e.g., from 1024 to 256 (rs = 4), and then train the model.\n",
    "    To make predictions using the model, we need tiles of the same size, resolution, and spatial feature representation.\n",
    "    Therefore, for predictions, we also need to downscale the image (resize = True).\n",
    "\n",
    "    Inputs:\n",
    "    - model: Trained CNN model for making the segmentation map.\n",
    "    - data: TIF file read as a numpy array to use as input for predictions.\n",
    "    - resize: If True, downscale the data using \"rs\".\n",
    "    - rs: Resizing coefficient (e.g., rs = 2 means downscale by a factor of 2).\n",
    "\n",
    "    Output:\n",
    "    - pred: Numpy array with the normalized predictions (1 = 100% probability, 0.3 = 30% probability of object).\n",
    "    '''\n",
    "\n",
    "    # Read the TIFF file using sliding window\n",
    "    data = tiff.imread(path)\n",
    "\n",
    "    # Define the size of the patch\n",
    "    patch_size = size\n",
    "\n",
    "    # Generate sliding windows of the specified patch size\n",
    "    windows = slidingwindow.generate(data, slidingwindow.DimOrder.HeightWidthChannel, patch_size, 0)\n",
    "\n",
    "    # Create an empty array to store the predictions\n",
    "    pred = np.zeros(data.shape)\n",
    "\n",
    "    # Iterate over the sliding windows and make predictions\n",
    "    for index, window in enumerate(tqdm(windows)):\n",
    "        # Extract the patch from the data\n",
    "        patch = data[windows[index].indices()]\n",
    "\n",
    "        # Preprocess the patch if necessary\n",
    "        patch = (patch - patch.min()) * (255.0 / (patch.max() - patch.min()))\n",
    "        patch = np.asarray(patch, dtype=np.float32) / 255\n",
    "        patch = patch.reshape(1, patch.shape[0], patch.shape[1], 1)\n",
    "\n",
    "    #     print('Predictions...')\n",
    "        # Make predictions for the patch\n",
    "        pred_patch = model.predict(patch) * 100\n",
    "    #     print('Predictions Done...\\n')\n",
    "        pred_patch = np.squeeze(pred_patch).astype(np.uint8)\n",
    "\n",
    "        # Assign the predicted patch to the corresponding location in the output array\n",
    "        pred[windows[index].indices()] = pred_patch\n",
    "\n",
    "    print('Saving...')\n",
    "    # Save the predicted image as a georeferenced TIFF\n",
    "    output_path = path[:-4]+'_CNN{}_3.tif'.format(size)\n",
    "    with rasterio.open(path) as src:\n",
    "        profile = src.profile\n",
    "        profile.update(count=1, dtype='uint8', nodata=0)\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            dst.write(pred.astype('uint8'), 1)\n",
    "\n",
    "    # Visualization\n",
    "    plt.imshow(pred)\n",
    "\n",
    "    return pred\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for path in tif_list[0:]:\n",
    "    predict_tif(model, path, 256)\n",
    "    break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raster to Vector"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tif_list"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### Train images and labels should correspond to each other within the list!\n",
    "#### That's why sometimes it's easier to read label list and then just add right extension to it:\n",
    "\n",
    "cnn_list=[]\n",
    "for x in tif_list:\n",
    "#     print(x)\n",
    "    path = x[:-4]+'_CNN256_2.tif'\n",
    "    if not os.path.exists(path):\n",
    "        print('Ooops with {}'.format(path))\n",
    "    cnn_list.append(path)\n",
    "print(cnn_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for path in cnn_list:\n",
    "\n",
    "    # Read the TIFF file using sliding window\n",
    "    data = tiff.imread(path)\n",
    "    print(data.shape)\n",
    "    data_filt = np.where(data<10, 0, 1)\n",
    "\n",
    "    print('Saving...')\n",
    "    # Save the predicted image as a georeferenced TIFF\n",
    "    output_path = path[:-4]+'_CNN{}_filt.tif'.format(size)\n",
    "    with rasterio.open(path) as src:\n",
    "        profile = src.profile\n",
    "        profile.update(count=1, dtype='uint8', nodata=0)\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            dst.write(data_filt.astype('uint8'), 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### Train images and labels should correspond to each other within the list!\n",
    "#### That's why sometimes it's easier to read label list and then just add right extension to it:\n",
    "\n",
    "cnn_list_filt=[]\n",
    "for x in tif_list:\n",
    "#     print(x)\n",
    "    path = x[:-4]+'_CNN256_CNN256_filt.tif'\n",
    "    if not os.path.exists(path):\n",
    "        print('Ooops with {}'.format(path))\n",
    "    cnn_list_filt.append(path)\n",
    "print(cnn_list_filt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# output_vector = input_raster[:-4]+'.shp'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import rasterio\n",
    "from shapely.geometry import shape, mapping\n",
    "import fiona\n",
    "\n",
    "def raster_to_vector(input_raster):\n",
    "    # Read the input raster\n",
    "    with rasterio.open(input_raster) as src:\n",
    "        image = src.read(1)  # Read the raster band\n",
    "        crs = src.crs  # Get the CRS from the input raster\n",
    "        transform = src.transform  # Get the transform from the input raster\n",
    "\n",
    "    # Create a collection of vector geometries from the raster\n",
    "    geoms = list(\n",
    "        shape(geometry) for geometry, value in rasterio.features.shapes(image, mask=None, transform=transform) if\n",
    "        value == 1)\n",
    "    output_vector = input_raster[:-4]+'.shp'\n",
    "    # Create the output vector file\n",
    "    schema = {'geometry': 'Polygon', 'properties': {'id': 'int'}}\n",
    "    with fiona.open(output_vector, 'w', 'ESRI Shapefile', schema=schema, crs=crs) as dst:\n",
    "        # Iterate over the geometries and add them to the vector file\n",
    "        for i, geom in enumerate(geoms):\n",
    "            feature = {\n",
    "                'geometry': mapping(geom),  # Convert geometry to a valid format\n",
    "                'properties': {'id': i}  # You can add properties to the vector features if needed\n",
    "            }\n",
    "            dst.write(feature)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for tif in cnn_list_filt:\n",
    "    raster_to_vector(tif)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### Train images and labels should correspond to each other within the list!\n",
    "#### That's why sometimes it's easier to read label list and then just add right extension to it:\n",
    "\n",
    "shp_list=[]\n",
    "for x in cnn_list_filt:\n",
    "#     print(x)\n",
    "    path = x[:-4]+'.shp'\n",
    "    if not os.path.exists(path):\n",
    "        print('Ooops with {}'.format(path))\n",
    "    shp_list.append(path)\n",
    "print(shp_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "def merge_shapefiles(input_files, output_file):\n",
    "    # Read the schema from the first input shapefile\n",
    "    with fiona.open(input_files[0], 'r') as input:\n",
    "        schema = input.schema.copy()\n",
    "        crs = input.crs\n",
    "\n",
    "    # Open the output shapefile in write mode using the same schema and CRS\n",
    "    with fiona.open(output_file, 'w', 'ESRI Shapefile', schema=schema, crs=crs) as output:\n",
    "        # Iterate over the input shapefiles\n",
    "        for input_file in input_files:\n",
    "            # Open each input shapefile in read mode\n",
    "            with fiona.open(input_file, 'r') as input:\n",
    "                # Iterate over the features in the input shapefile\n",
    "                for feature in input:\n",
    "                    # Convert the geometry to a shapely object\n",
    "                    geometry = shape(feature['geometry'])\n",
    "                    \n",
    "                    # Add the feature to the output shapefile\n",
    "                    output.write({\n",
    "                        'geometry': mapping(geometry),\n",
    "                        'properties': feature['properties'],\n",
    "                    })\n",
    "\n",
    "    print(\"Shapefiles merged successfully!\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "merge_shapefiles(shp_list, '/media/irro/Irro/HumanFootprint/Kirby_DSM_10cm_CNN256.shp')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pred for Test file"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import slidingwindow\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = '/media/irro/Irro/HumanFootprint/test.tif'\n",
    "data = tiff.imread(path)[100:356, 100:356]\n",
    "\n",
    "patch = (data-data.min())\n",
    "patch = (patch - patch.min()) * (255.0 / (patch.max() - patch.min()))\n",
    "\n",
    "data = np.asarray(patch, dtype=np.float32)/255\n",
    "data = data.reshape(1, data.shape[0], data.shape[1], 1)\n",
    "\n",
    "pred = model.predict(data)*100\n",
    "pred = (np.squeeze(pred)).astype(np.uint8)\n",
    "\n",
    "# Prediction vizualization:\n",
    "f, axarr = plt.subplots(1,2,figsize=(20,20))\n",
    "axarr[0].imshow(np.squeeze(data))\n",
    "axarr[1].imshow(pred)\n",
    "\n",
    "# cv2.imwrite('/media/irro/Irro/HumanFootprint/test_CNN.png', pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting all TIF files in directory"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "############ Preparing a list of files for predictions\n",
    "#### Root directory with tif files:\n",
    "test_dir = '/media/irro/Irro/Irina/WellPads/CHM_testing'\n",
    "\n",
    "#### Making a list of tifs which NOT end with... \"CNN256.tif\" - you should put your own extension\n",
    "test_list = [os.path.join(test_dir,files) for files in os.listdir(test_dir) if files.endswith(\".tif\")\n",
    "            and not files.endswith(\"CNN256.tif\")]\n",
    "print(test_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "################ Predictions for the single tif (with further saving)\n",
    "predict_tif(model, '/media/irro/Irro/Irina/WellPads/CHM_testing/CHM_9.tif', name = '_over0.5', overla = 0.5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "######## Predictions for list of tif files (one by one)\n",
    "for tif in test_list:\n",
    "    predict_tif(model, tif, name = '_over0.5', overla = 0.5)\n",
    "    print('\\nDone: {}'.format(tif))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Prediction vizualization:\n",
    "f, axarr = plt.subplots(1,figsize=(20,20))\n",
    "axarr.imshow(tiff.imread(path)*255)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Prediction vizualization:\n",
    "f, axarr = plt.subplots(1,figsize=(20,20))\n",
    "axarr.imshow(pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# path = '/media/irro/Irro/Irina/Rasters/CHMs/CHM_0.tif'\n",
    "# predict_lines(model, path, 500, 500, resize = True)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
